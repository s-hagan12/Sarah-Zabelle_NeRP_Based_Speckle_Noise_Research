{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f873274a-f018-496d-b372-9d9d8748fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook will allow you to run INR using a prior from multi-look measurements with Speckle Noise\n",
    "#Paramters should be configured in the speckle_recon config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06552b9f-a849-439c-98b3-2f4156bf1509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from typing import Tuple, List\n",
    "import torch\n",
    "import pickle\n",
    "from NeRP_main.networks import Positional_Encoder, FFN, SIREN\n",
    "from NeRP_main.utils import get_config, prepare_sub_folder, get_data_loader\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from NeRP_main.data import create_grid\n",
    "import torch.nn as nn\n",
    "\n",
    "from my_utils import *\n",
    "from multilook_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c999488-0e64-42c6-ad77-232c59a401c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configs\n",
    "config = get_config(\"speckle_recon.yaml\")\n",
    "device = torch.device('cpu')\n",
    "img_size = config[\"img_size\"]\n",
    "max_iter = config['max_iter']\n",
    "num_looks = config[\"num_looks\"]\n",
    "prior = True #Enable to use a prior generated using a low pass filter\n",
    "better_prior = True #Enable to use a prior generated by adding noise to the original image. This can be used sequentially\n",
    "if better_prior:\n",
    "    #Parameters for Gaussian noise\n",
    "    mean = 0\n",
    "    sigma = 0.05\n",
    "display = False #Enable to see the training/test losses and PSNR while the model is training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a79d3c-e3da-4bb9-ac41-e42a011c3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data - no additive noise\n",
    "data = np.load(\"/Users/sarahhagan/Desktop/NeRP Research/Speckle_noise_datasets/coherent_just_speckle_cifar.npz\")\n",
    "A_loaded = data[\"A\"] # m * n\n",
    "X_loaded = data[\"X\"] # N * n\n",
    "Y_loaded = data[\"Y\"] # N * L * m\n",
    "m = A_loaded.shape[0]\n",
    "n = A_loaded.shape[1]\n",
    "N = X_loaded.shape[0]\n",
    "L = Y_loaded.shape[1]\n",
    "print(\"m =\",m,\"n =\",n,\"N =\",N,\"L =\",L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f58424-b73f-4c10-9385-a1e97de98f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSpeckleLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleSpeckleLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, targets, n=1):\n",
    "        # Compute the loss\n",
    "        epsilon = 1e-8\n",
    "        clamped = torch.clamp(input, min=epsilon)\n",
    "        loss = 0\n",
    "        for i in range(n):\n",
    "            loss += torch.sum(torch.log(clamped) + (targets[i]**2) / (2 * clamped**2))\n",
    "        return loss/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf517ac-188e-481b-9b67-a63eff873783",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_tensor = torch.from_numpy(A_loaded).to(torch.float32)\n",
    "learned_models = []\n",
    "prior_train_psnr_list = []\n",
    "prior_test_psnr_list = []\n",
    "better_prior_train_psnr_list = []\n",
    "better_prior_test_psnr_list = []\n",
    "target_train_psnr_list = []\n",
    "target_test_psnr_list = []\n",
    "\n",
    "if prior:\n",
    "    #Create DCT matrix to be used with all images\n",
    "    Fm = dct_matrix(img_size)\n",
    "    cutoff_idx = config['cutoff_idx'] #Low Pass Filter Cutoff\n",
    "    FmI = Fm[:cutoff_idx] #Create Low Pass Filtered DCT transforms\n",
    "    FmI_T = FmI.transpose() \n",
    "    B = np.kron(FmI_T, FmI_T) #Kronecker Product\n",
    "    print(\"B:\", B.shape)\n",
    "    AB = np.matmul(A_loaded, B)\n",
    "\n",
    "#Change the range to alter which images to run INR over\n",
    "for i in range(0, 50):\n",
    "    truth = X_loaded[i].reshape(img_size,img_size)\n",
    "    measurements = Y_loaded[i][:num_looks]\n",
    "    print(measurements.shape)\n",
    "    print(A_tensor.shape)\n",
    "    print(\"--------------------------------- Image \", i, \"---------------------------------\")\n",
    "    plt.imshow(truth, cmap='gray')\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.show()\n",
    "    plt.imshow(np.abs(measurements[0].reshape(img_size,img_size)), cmap='gray')\n",
    "    plt.title(\"With Speckle\")\n",
    "    plt.show()\n",
    "\n",
    "    # Setup input encoder:\n",
    "    encoder = Positional_Encoder(config['encoder'])\n",
    "    # Setup model\n",
    "    if config['model'] == 'SIREN':\n",
    "        model = SIREN(config['net'])\n",
    "    elif config['model'] == 'FFN':\n",
    "        model = FFN(config['net'])\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    #Set up optimiser\n",
    "    if config['optimizer'] == 'Adam':\n",
    "            optim = torch.optim.Adam(model.parameters(), lr=config['lr'], betas=(config['beta1'], config['beta2']), weight_decay=config['weight_decay'])\n",
    "    else:\n",
    "        NotImplementedError\n",
    "\n",
    "    # Setup loss function\n",
    "    if config['loss'] == 'L2':\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "    elif config['loss'] == 'L1':\n",
    "        loss_fn = torch.nn.L1Loss()\n",
    "    elif config['loss'] == 'simple_speckle':\n",
    "        loss_fn = SimpleSpeckleLoss()\n",
    "    else:\n",
    "        NotImplementedError\n",
    "\n",
    "    if prior:\n",
    "        if config['loss'] == 'L2' or config['loss'] == 'simple_speckle':\n",
    "            prior_loss_fn = torch.nn.MSELoss()\n",
    "        elif config['loss'] == 'L1':\n",
    "            prior_loss_fn = torch.nn.L1Loss()\n",
    "        else:\n",
    "            NotImplementedError\n",
    "        print(\"Prior:\")\n",
    "        #Create a \"prior image\" using DCT\n",
    "        prior_measurements = 0\n",
    "        for i in range(num_looks):\n",
    "            prior_measurements += measurements[i]**2 \n",
    "        prior_measurements /= num_looks\n",
    "        prior_measurements = prior_measurements**0.5\n",
    "        v_x_tilde, residuals, rank, singular_values = np.linalg.lstsq(AB, np.abs(prior_measurements)) #Least Squares\n",
    "        x_tilde = undo_vec(v_x_tilde, cutoff_idx, cutoff_idx) #Solution in the Frequency Domain\n",
    "        x_hat = np.matmul(np.matmul(FmI_T, x_tilde), FmI) #Solution in the Image Domain\n",
    "        \n",
    "        plt.imshow(x_hat, cmap=\"gray\")\n",
    "        plt.title(\"Prior Reconstruction\")\n",
    "        plt.show()\n",
    "\n",
    "        prior_loss = 0.5 * np.sum((x_hat - truth)**2)/(img_size**2)\n",
    "        prior_psnr = - 10 * np.log10(2 * prior_loss).item()\n",
    "        print(\"Prior PSNR: \", prior_psnr)\n",
    "\n",
    "        #Embed the prior image\n",
    "        prior_img = torch.from_numpy(x_hat).to(torch.float32).reshape(1, img_size, img_size, 1)\n",
    "        dataset = myImageDataset_2D(truth,img_size)\n",
    "        data_loader = DataLoader(dataset=dataset, \n",
    "                            batch_size=config[\"batch_size\"], \n",
    "                            shuffle=True, \n",
    "                            drop_last=True, \n",
    "                            num_workers=0)\n",
    "        model, prior_train_psnr, prior_test_psnr = train_gauss(model, optim, prior_loss_fn, data_loader, prior_img, encoder, config, A_tensor=A_tensor, display=display, display_img=False, learn_from_proj=False, device=\"cpu\", max_iter=max_iter)\n",
    "        prior_train_psnr_list.append(prior_train_psnr)\n",
    "        prior_test_psnr_list.append(prior_test_psnr)\n",
    "        \n",
    "    if better_prior:\n",
    "        if config['loss'] == 'L2' or config['loss'] == 'simple_speckle':\n",
    "            prior_loss_fn = torch.nn.MSELoss()\n",
    "        elif config['loss'] == 'L1':\n",
    "            prior_loss_fn = torch.nn.L1Loss()\n",
    "        else:\n",
    "            NotImplementedError\n",
    "        print(\"Prior:\")\n",
    "        \n",
    "        #Create a \"prior image\" by adding noise to the ground truth\n",
    "        \n",
    "        # Generate Gaussian noise with the same shape as the image\n",
    "        gaussian_noise = np.random.normal(mean, sigma, truth.shape).astype(np.float32)\n",
    "        \n",
    "        # Add the noise to the image\n",
    "        x_hat = np.add(truth, gaussian_noise)\n",
    "        \n",
    "        plt.imshow(x_hat, cmap=\"gray\")\n",
    "        plt.title(\"Better Prior\")\n",
    "        plt.show()\n",
    "\n",
    "        prior_loss = 0.5 * np.sum((x_hat - truth)**2)/(img_size**2)\n",
    "        prior_psnr = - 10 * np.log10(2 * prior_loss).item()\n",
    "        print(\"Prior PSNR: \", prior_psnr)\n",
    "\n",
    "        #Embed the prior image\n",
    "        prior_img = torch.from_numpy(x_hat).to(torch.float32).reshape(1, img_size, img_size, 1)\n",
    "        dataset = myImageDataset_2D(truth,img_size)\n",
    "        data_loader = DataLoader(dataset=dataset, \n",
    "                            batch_size=config[\"batch_size\"], \n",
    "                            shuffle=True, \n",
    "                            drop_last=True, \n",
    "                            num_workers=0)\n",
    "        model, prior_train_psnr, prior_test_psnr = train_gauss(model, optim, loss_fn, data_loader, prior_img, encoder, config, A_tensor=A_tensor, display=True, display_img=False, learn_from_proj=False, device=\"cpu\", max_iter=max_iter)\n",
    "        better_prior_train_psnr_list.append(prior_train_psnr)\n",
    "        better_prior_test_psnr_list.append(prior_test_psnr)\n",
    "        \n",
    "    #Train from the sensor measurements\n",
    "    print(\"Target:\")\n",
    "    measurements = torch.from_numpy(measurements).to(torch.float32)\n",
    "    measurements = measurements.reshape(num_looks, 1, img_size, img_size, 1)#remove this line later\n",
    "    inverse_dataset = myImageDataset_2D(truth,img_size)\n",
    "    inverse_data_loader = DataLoader(dataset=inverse_dataset, \n",
    "                        batch_size=config[\"batch_size\"], \n",
    "                        shuffle=True, \n",
    "                        drop_last=True, \n",
    "                        num_workers=0)\n",
    "    model, target_train_psnr, target_test_psnr = train_multilook_gauss(model, optim, loss_fn, inverse_data_loader, measurements, encoder, config, A_tensor=A_tensor, display=True, display_img=False, learn_from_proj=False, device=\"cpu\", max_iter=max_iter)\n",
    "    learned_models.append(model)\n",
    "    target_train_psnr_list.append(target_train_psnr)\n",
    "    target_test_psnr_list.append(target_test_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3590aa-f7d3-4780-b752-d3b03c3c2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the graphs of the PSNRs\n",
    "num_imgs = len(target_train_psnr_list)\n",
    "num_imgs =1\n",
    "if prior:\n",
    "    prior_train_indices = range(0, len(prior_train_psnr_list[0])*config['log_iter'], config['log_iter'])\n",
    "    prior_test_indices = range(0, len(prior_test_psnr_list[0])*config['val_iter'], config['val_iter'])\n",
    "if better_prior:\n",
    "    better_prior_train_indices = range(0, len(better_prior_train_psnr_list[0])*config['log_iter'], config['log_iter'])\n",
    "    better_prior_test_indices = range(0, len(better_prior_test_psnr_list[0])*config['val_iter'], config['val_iter'])\n",
    "target_train_indices = range(0, len(target_train_psnr_list[0])*config['log_iter'], config['log_iter'])\n",
    "target_test_indices = range(0, len(target_test_psnr_list[0])*config['val_iter'], config['val_iter'])\n",
    "colors = plt.get_cmap('tab20', num_imgs)\n",
    "\n",
    "#Prior Graph\n",
    "if prior:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(num_imgs):\n",
    "        color = colors(i)\n",
    "        plt.plot(prior_train_indices, prior_train_psnr_list[i], color=color, linestyle='--')\n",
    "        plt.plot(prior_test_indices, prior_test_psnr_list[i], color=color, linestyle='-')\n",
    "    plt.title('Test vs Train PSNR for Prior images')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('PSNR (dB)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "if prior:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(num_imgs):\n",
    "        color = colors(i)\n",
    "        plt.plot(better_prior_train_indices, better_prior_train_psnr_list[i], color=color, linestyle='--')\n",
    "        plt.plot(better_prior_test_indices, better_prior_test_psnr_list[i], color=color, linestyle='-')\n",
    "    plt.title('Test vs Train PSNR for Better Prior images')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('PSNR (dB)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "#Target graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(num_imgs):\n",
    "    color = colors(i)\n",
    "    plt.plot(target_train_indices, target_train_psnr_list[i], color=color, linestyle='--')\n",
    "    plt.plot(target_test_indices, target_test_psnr_list[i], color=color, linestyle='-')\n",
    "plt.title('Test vs Train PSNR for Target images')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('PSNR (dB)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4499a97-314b-4c43-a573-17a17e56e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prior:\n",
    "    avg_prior_train_psnr = sum([lst[-1] for lst in prior_train_psnr_list])/len(prior_train_psnr_list)\n",
    "    avg_prior_test_psnr = sum([lst[-1] for lst in prior_test_psnr_list])/len(prior_test_psnr_list)\n",
    "avg_target_train_psnr = sum([lst[-1] for lst in target_train_psnr_list])/len(target_train_psnr_list)\n",
    "avg_target_test_psnr = sum([lst[-1] for lst in target_test_psnr_list])/len(target_test_psnr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b347b7e3-a19c-4bb0-bf49-77b7166b860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prior or better_prior:\n",
    "    print(f\"Avg Prior Train PSNR: {avg_prior_train_psnr:.2f}\")\n",
    "    print(f\"Avg Prior Test PSNR:  {avg_prior_test_psnr:.2f}\")\n",
    "print(f\"Avg Target Train PSNR: {avg_target_train_psnr:.2f}\")\n",
    "print(f\"Avg Target Test PSNR:  {avg_target_test_psnr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2e634e-859c-4504-b584-a897fbac0031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b7b327-f0b9-420e-a4c2-a3a3cdb2ab15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268431c-98e9-436b-957c-3b316a4d5c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f4752-d6ac-427f-b6c1-c42af2382a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ed6a7-21c1-4a56-857e-74373bb71f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951b56b-c802-4507-8014-c805e14bd686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558223d3-40ca-42c6-b065-a82051501a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a696f-d21c-495c-acb1-4ea635870ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
